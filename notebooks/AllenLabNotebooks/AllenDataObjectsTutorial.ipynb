{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example cache directory path, it determines where downloaded data will be stored\n",
    "output_dir = '/home/marcush/Data/AllenData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this path determines where downloaded data will be stored\n",
    "manifest_path = os.path.join(output_dir, \"manifest.json\")\n",
    "\n",
    "cache = EcephysProjectCache.from_warehouse(manifest=manifest_path)\n",
    "\n",
    "print(cache.get_all_session_types())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = cache.get_session_table()\n",
    "brain_observatory_type_sessions = sessions[sessions[\"session_type\"] == \"brain_observatory_1.1\"]\n",
    "brain_observatory_type_sessions.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/marcush/Data/AllenData/PerSessionUnitYield.pkl\"\n",
    "loaded_all_unit_counts = pd.read_pickle(file_path)\n",
    "\n",
    "\n",
    "print(f\"Recorded Areas:\")\n",
    "print(loaded_all_unit_counts.keys())\n",
    "\n",
    "print(\"Number of units per recording, per area:\")\n",
    "print(loaded_all_unit_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = 791319847\n",
    "session = cache.get_session_data(session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_observatory_type_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_format = session.structurewise_unit_counts.to_frame().T  # Transpose the DataFrame\n",
    "\n",
    "row_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.structurewise_unit_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presentations = session.get_stimulus_table(\"flashes\")\n",
    "units = session.units[session.units[\"ecephys_structure_acronym\"] == 'VISp']\n",
    "\n",
    "time_step = 0.01\n",
    "time_bins = np.arange(-0.1, 0.5 + time_step, time_step)\n",
    "\n",
    "histograms = session.presentationwise_spike_counts(\n",
    "    stimulus_presentation_ids=presentations.index.values,  \n",
    "    bin_edges=time_bins,\n",
    "    unit_ids=units.index.values\n",
    ")\n",
    "\n",
    "histograms.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms.shape # trial, time, unit. use 'histograms.coords' to confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_histograms = histograms.mean(dim=\"stimulus_presentation_id\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.pcolormesh(\n",
    "    mean_histograms[\"time_relative_to_stimulus_onset\"], \n",
    "    np.arange(mean_histograms[\"unit_id\"].size),\n",
    "    mean_histograms.T, \n",
    "    vmin=0,\n",
    "    vmax=1\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"unit\", fontsize=24)\n",
    "ax.set_xlabel(\"time relative to stimulus onset (s)\", fontsize=24)\n",
    "ax.set_title(\"peristimulus time histograms for VISp units on flash presentations\", fontsize=24)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(histograms)\n",
    "\n",
    "new_hist = np.array(histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_hist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_presentations = session.get_stimulus_table(\"natural_scenes\")\n",
    "visp_units = session.units[session.units[\"ecephys_structure_acronym\"] == \"VISp\"]\n",
    "\n",
    "spikes = session.presentationwise_spike_times(\n",
    "    stimulus_presentation_ids=scene_presentations.index.values,\n",
    "    unit_ids=visp_units.index.values[:]\n",
    ")\n",
    "\n",
    "spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary where keys are tuples of (trial, unit) and values are lists of spike times\n",
    "grouped = spikes.groupby(['stimulus_presentation_id', 'unit_id'])\n",
    "spike_times_dict = grouped['time_since_stimulus_presentation_onset'].apply(list).to_dict()\n",
    "# E.g.: trial_unit_key = (scene_presentations.index.values[0], visp_units.index.values[3]); spike_times = spike_times_dict[trial_unit_key]; print(spike_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_unit_key = (scene_presentations.index.values[0], visp_units.index.values[3])\n",
    "spike_times = spike_times_dict[trial_unit_key]\n",
    "\n",
    "print(spike_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_elements, counts = np.unique(scene_presentations['stimulus_condition_id'], return_counts=True)\n",
    "print(unique_elements)  # List of unique elements\n",
    "print(counts)  # Counts of each unique element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes[\"count\"] = np.zeros(spikes.shape[0])\n",
    "spikes = spikes.groupby([\"stimulus_presentation_id\", \"unit_id\"]).count()\n",
    "\n",
    "design = pd.pivot_table(\n",
    "    spikes, \n",
    "    values=\"count\", \n",
    "    index=\"stimulus_presentation_id\", \n",
    "    columns=\"unit_id\", \n",
    "    fill_value=0.0,\n",
    "    aggfunc=np.sum\n",
    ")\n",
    "\n",
    "design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = scene_presentations.loc[design.index.values, \"frame\"]\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_arr = design.values.astype(float)\n",
    "targets_arr = targets.values.astype(int)\n",
    "\n",
    "labels = np.unique(targets_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presentations.index.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Using kernalized SVC\n",
    "\"\"\"\"\"\n",
    "\n",
    "accuracies = []\n",
    "confusions = []\n",
    "\n",
    "for train_indices, test_indices in KFold(n_splits=5).split(design_arr):\n",
    "    \n",
    "    clf = svm.SVC(gamma=\"scale\", kernel=\"rbf\")\n",
    "    clf.fit(design_arr[train_indices], targets_arr[train_indices])\n",
    "    \n",
    "    test_targets = targets_arr[test_indices]\n",
    "    test_predictions = clf.predict(design_arr[test_indices])\n",
    "    \n",
    "    accuracy = 1 - (np.count_nonzero(test_predictions - test_targets) / test_predictions.size)\n",
    "    print(accuracy)\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    confusions.append(confusion_matrix(y_true=test_targets, y_pred=test_predictions, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Using logistic regression\n",
    "\"\"\"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "accuracies = []\n",
    "confusions = []\n",
    "\n",
    "for train_indices, test_indices in KFold(n_splits=5).split(design_arr):\n",
    "    \n",
    "    # Replace SVM classifier with Logistic Regression\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(design_arr[train_indices], targets_arr[train_indices])\n",
    "    \n",
    "    test_targets = targets_arr[test_indices]\n",
    "    test_predictions = clf.predict(design_arr[test_indices])\n",
    "    \n",
    "    accuracy = 1 - (np.count_nonzero(test_predictions - test_targets) / test_predictions.size)\n",
    "    print(accuracy)\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    confusions.append(confusion_matrix(y_true=test_targets, y_pred=test_predictions, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"mean accuracy: {np.mean(accuracies)}\")\n",
    "print(f\"chance: {1/labels.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_confusion = np.mean(confusions, axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "img = ax.imshow(mean_confusion)\n",
    "fig.colorbar(img)\n",
    "\n",
    "ax.set_ylabel(\"actual\")\n",
    "ax.set_xlabel(\"predicted\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = labels[np.argmax(np.diag(mean_confusion))]\n",
    "worst = labels[np.argmin(np.diag(mean_confusion))]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "best_image = cache.get_natural_scene_template(best)\n",
    "ax[0].imshow(best_image, cmap=plt.cm.gray)\n",
    "ax[0].set_title(\"most decodable\", fontsize=24)\n",
    "\n",
    "worst_image = cache.get_natural_scene_template(worst)\n",
    "ax[1].imshow(worst_image, cmap=plt.cm.gray)\n",
    "ax[1].set_title(\"least decodable\", fontsize=24)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncontrol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
