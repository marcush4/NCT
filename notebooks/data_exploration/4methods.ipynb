{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from dca.dca import DynamicalComponentsAnalysis\n",
    "from dca_research.kca import KalmanComponentsAnalysis\n",
    "from dca_research.lqg import LQGComponentsAnalysis\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.signal import find_peaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/akumar/nse/neural_control')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders import load_peanut\n",
    "from loaders import segment_peanut\n",
    "from loaders import location_bin_peanut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loadings(U, d=1):\n",
    "    # Sum over components\n",
    "    U = np.sum(np.power(np.abs(U), 2), axis=-1)\n",
    "    # Reshape and then sum over neurons\n",
    "    U = np.reshape(U, (d, -1))\n",
    "    loadings = np.sum(U, axis=0)\n",
    "    loadings /= np.max(loadings)\n",
    "    return loadings\n",
    "    \n",
    "def getLoadingsonTransitions(X):\n",
    "    \"\"\"fit DCA/PCA/KCA to each of the trialized transitions\"\"\"\n",
    "    DCAmodel = DynamicalComponentsAnalysis(d=2, T=3)\n",
    "    PCAmodel = PCA(n_components=2)\n",
    "    KCAmodel = KalmanComponentsAnalysis(d=2, T=3)\n",
    "    FCAmodel = LQGComponentsAnalysis(d=2, T=3)\n",
    "    DCAmodel.fit(X)\n",
    "    KCAmodel.fit(X)\n",
    "    FCAmodel.fit(X)\n",
    "    extended = X[0]\n",
    "    for transit in X[1:]:\n",
    "        extended = np.vstack((extended,transit))\n",
    "    PCAmodel.fit(extended)\n",
    "    \n",
    "    PCA_loading = calc_loadings(PCAmodel.components_.T) # np.log(calc_loadings(PCAmodel.components_.T))\n",
    "    DCA_loading = calc_loadings(DCAmodel.coef_) #np.log(calc_loadings(DCAmodel.coef_))\n",
    "    KCA_loading = calc_loadings(KCAmodel.coef_)\n",
    "    FCA_loading = calc_loadings(FCAmodel.coef_)\n",
    "\n",
    "    return PCA_loading, DCA_loading, KCA_loading, FCA_loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_df = pd.read_pickle(\"/home/akumar/nse/neural_control/data/peanut_segmented_supervised.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/akumar/nse/DCA_research/dca_research/lqg.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cross_cov_mats = torch.tensor(cross_cov_mats)\n",
      "/home/akumar/nse/DCA_research/dca_research/lqg.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cross_cov_mats = torch.tensor(cross_cov_mats)\n",
      "1it [00:10, 10.86s/it]/home/akumar/nse/DCA_research/dca_research/lqg.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cross_cov_mats = torch.tensor(cross_cov_mats)\n",
      "/home/akumar/nse/DCA_research/dca_research/lqg.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cross_cov_mats = torch.tensor(cross_cov_mats)\n",
      "2it [00:20,  9.99s/it]/home/akumar/nse/DCA_research/dca_research/lqg.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cross_cov_mats = torch.tensor(cross_cov_mats)\n",
      "/home/akumar/nse/DCA_research/dca_research/lqg.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cross_cov_mats = torch.tensor(cross_cov_mats)\n",
      "3it [00:30, 10.29s/it]/home/akumar/nse/DCA_research/dca_research/lqg.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cross_cov_mats = torch.tensor(cross_cov_mats)\n",
      "/home/akumar/nse/DCA_research/dca_research/lqg.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cross_cov_mats = torch.tensor(cross_cov_mats)\n",
      "4it [00:41, 10.53s/it]/home/akumar/nse/DCA_research/dca_research/lqg.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cross_cov_mats = torch.tensor(cross_cov_mats)\n",
      "/home/akumar/nse/DCA_research/dca_research/lqg.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cross_cov_mats = torch.tensor(cross_cov_mats)\n",
      "5it [00:53, 10.84s/it]/home/akumar/nse/DCA_research/dca_research/lqg.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cross_cov_mats = torch.tensor(cross_cov_mats)\n",
      "/home/akumar/nse/DCA_research/dca_research/lqg.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cross_cov_mats = torch.tensor(cross_cov_mats)\n",
      "6it [01:05, 11.23s/it]/home/akumar/nse/DCA_research/dca_research/lqg.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cross_cov_mats = torch.tensor(cross_cov_mats)\n",
      "/home/akumar/nse/DCA_research/dca_research/lqg.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cross_cov_mats = torch.tensor(cross_cov_mats)\n",
      "7it [01:16, 11.29s/it]/home/akumar/nse/DCA_research/dca_research/lqg.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cross_cov_mats = torch.tensor(cross_cov_mats)\n",
      "/home/akumar/nse/DCA_research/dca_research/lqg.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cross_cov_mats = torch.tensor(cross_cov_mats)\n",
      "8it [01:25, 10.67s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16]\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for i, epoch in tqdm(enumerate(epochs)):\n",
    "\n",
    "    dat =  load_peanut('/mnt/Secondary/data/peanut/data_dict_peanut_day14.obj', epoch, spike_threshold=200 , bin_width=1, boxcox=None,\n",
    "                       speed_threshold=4)\n",
    "\n",
    "    transitions1, transitions2 = segment_peanut(dat, '/mnt/Secondary/data/peanut/linearization_dict_peanut_day14.obj', epoch) \n",
    "\n",
    "    spike_rates = dat['spike_rates']  \n",
    "    #Fit DCA/PCA on both kinds of transitions\n",
    "    spike_rates_list_transition1 = [spike_rates[transit] for transit in transitions1]\n",
    "\n",
    "    PCA_loading_1, DCA_loading_1, KCA_loading_1, FCA_loadings1 = getLoadingsonTransitions(spike_rates_list_transition1)\n",
    "    spike_rates_list_transition2 = [spike_rates[transit] for transit in transitions2]\n",
    "    PCA_loading_2, DCA_loading_2, KCA_loading_2, FCA_loadings2 = getLoadingsonTransitions(spike_rates_list_transition2)\n",
    "\n",
    "    SS_loading_1 =  supervised_df.loc[(supervised_df['epoch'] == epoch) & \\\n",
    "                                      (supervised_df['fold_idx'] == 1) &\\\n",
    "                                      (supervised_df['transition_type'] == 1) ][\"loadings\"].iloc[0]\n",
    "    SS_loading_2 =  supervised_df.loc[(supervised_df['epoch'] == epoch) & \\\n",
    "                                      (supervised_df['fold_idx'] == 1) &\\\n",
    "                                      (supervised_df['transition_type'] == 2) ][\"loadings\"].iloc[0]\n",
    "\n",
    "    # PCA_loading_3, DCA_loading_3, KCA_loading_3, FCA_loadings3 = getLoadingsonTransitions(spike_rates)\n",
    "    PCA_loading_3 = np.nan\n",
    "    DCA_loading_3 = np.nan\n",
    "    KCA_loading_3 = np.nan\n",
    "    FCA_loadings3 = np.nan\n",
    "    #print(\"Epoch {0}\".format(epoch))\n",
    "    #print(PCA_loading_1.shape, DCA_loading_1.shape, SS_loading_1.shape, KCA_loading_1.shape)\n",
    "    transitions, bins_ = location_bin_peanut('/mnt/Secondary/data/peanut/data_dict_peanut_day14.obj',\n",
    "                                             '/mnt/Secondary/data/peanut/linearization_dict_peanut_day14.obj',\n",
    "                                             epoch=epoch, spike_threshold=200)\n",
    "\n",
    "    num_peaks = []    \n",
    "    \n",
    "    for transition, bins, dcaloading, pcaloading, kcaloading, ssloading, tran_idx \\\n",
    "        in zip(transitions, bins_, [DCA_loading_1, DCA_loading_2],[PCA_loading_1, PCA_loading_2],\\\n",
    "                                   [KCA_loading_1, KCA_loading_2],[SS_loading_1, SS_loading_2],[1,2]):\n",
    "        num_peaks_transition = np.zeros(transition.shape[1])    \n",
    "        for neuron_idx in range(transition.shape[1]):\n",
    "            peak_indices = find_peaks(transition[:,neuron_idx])[0]\n",
    "            reg = LinearRegression().fit(bins[1:, np.newaxis], transition[:,neuron_idx])\n",
    "            predicted_line = reg.intercept_ + np.multiply(bins[1:],  np.squeeze(reg.coef_))\n",
    "            above_fit_line_peak_idxs = peak_indices[transition[:,neuron_idx][peak_indices] > predicted_line[peak_indices]]\n",
    "            num_peaks_transition[neuron_idx] = len(above_fit_line_peak_idxs)\n",
    "        num_peaks.append(num_peaks_transition)\n",
    "\n",
    "    result = {'epoch':epoch, 'num_peaks':num_peaks, 'PCA_loadings':[PCA_loading_1, PCA_loading_2, PCA_loading_3], \n",
    "              'DCA_loadings':[DCA_loading_1, DCA_loading_2, DCA_loading_3], 'KCA_loadings':[KCA_loading_1, KCA_loading_2, KCA_loading_3], \n",
    "              'SS_loadings':[SS_loading_1, SS_loading_2], 'FCA_loadings':[FCA_loadings1, FCA_loadings2, FCA_loadings3]} \n",
    "    \n",
    "    results_list.append(result)\n",
    "        #saved_name = \"DistributionOfLoadingsByPFNum/\"+ \"Epoch\" + str(epoch) + \"Transition\" + str(tran_idx) + \".png\"\n",
    "        #plt.savefig(saved_name)\n",
    "        #plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 4, figsize=(16, 8))\n",
    "epochs = [2, 4, 6, 8, 10, 12, 14, 16]\n",
    "for i, epoch in enumerate(epochs):\n",
    "        a = ax[np.unravel_index(i, (2, 4))]\n",
    "        a.boxplot([kcaloading[num_peaks == 1],kcaloading[num_peaks != 1],\\\n",
    "                        pcaloading[num_peaks == 1],pcaloading[num_peaks != 1],\\\n",
    "                        ssloading[num_peaks == 1],ssloading[num_peaks != 1],\\\n",
    "                        dcaloading[num_peaks == 1],dcaloading[num_peaks != 1]],\\\n",
    "                        positions=range(1, 16,2))\n",
    "        a.set_xticks([1, 3, 5, 7, 9, 11, 13, 15])\n",
    "        a.set_xticklabels(['KCA 1PF', 'KCA >1PF', 'PCA 1PF', 'PCA >1PF', 'SS 1PF', 'SS >1PF', 'DCA 1PF', 'DCA >1PF'])\n",
    "        a.set_ylabel(\"Loadings\")\n",
    "        a.set_title(\"Distribution of loadings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
