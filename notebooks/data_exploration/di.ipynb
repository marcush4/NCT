{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders import load_sabes\n",
    "from segmentation import reach_segment_sabes\n",
    "from gaussian_util import gaussian_DI, gaussian_DI_trialized\n",
    "from subspaces import estimate_autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indy_files = glob('/mnt/Secondary/data/sabes/indy*')\n",
    "loco_files = glob('/mnt/Secondary/data/sabes/loco*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M1 --> behavior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_times = {'indy_20160426_01': 0,\n",
    "               'indy_20160622_01':1700,\n",
    "               'indy_20160624_03': 500,\n",
    "               'indy_20160627_01': 0,\n",
    "               'indy_20160630_01': 0,\n",
    "               'indy_20160915_01': 0,\n",
    "               'indy_20160921_01': 0,\n",
    "               'indy_20160930_02': 0,\n",
    "               'indy_20160930_05': 300,\n",
    "               'indy_20161005_06': 0,\n",
    "               'indy_20161006_02': 350,\n",
    "               'indy_20161007_02': 950,\n",
    "               'indy_20161011_03': 0,\n",
    "               'indy_20161013_03': 0,\n",
    "               'indy_20161014_04': 0,\n",
    "               'indy_20161017_02': 0,\n",
    "               'indy_20161024_03': 0,\n",
    "               'indy_20161025_04': 0,\n",
    "               'indy_20161026_03': 0,\n",
    "               'indy_20161027_03': 500,\n",
    "               'indy_20161206_02': 5500,\n",
    "               'indy_20161207_02': 0,\n",
    "               'indy_20161212_02': 0,\n",
    "               'indy_20161220_02': 0,\n",
    "               'indy_20170123_02': 0,\n",
    "               'indy_20170124_01': 0,\n",
    "               'indy_20170127_03': 0,\n",
    "               'indy_20170131_02': 0,\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24769/649930829.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindy_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_sabes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spike_rates'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'behavior'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nse/neural_control/loaders.py\u001b[0m in \u001b[0;36mload_sabes\u001b[0;34m(filename, bin_width, boxcox, filter_fn, filter_kwargs, spike_threshold, std_behavior, region, get_dof_only, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         spike_rates = postprocess_spikes(spike_times, T, bin_width, boxcox,\n\u001b[0;32m--> 327\u001b[0;31m                                          filter_fn, filter_kwargs, spike_threshold, high_pass=True)\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spike_rates'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspike_rates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nse/neural_control/loaders.py\u001b[0m in \u001b[0;36mpostprocess_spikes\u001b[0;34m(spike_times, T, bin_width, boxcox, filter_fn, filter_kwargs, spike_threshold, trial_threshold, high_pass)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mboxcox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 spike_counts = np.array([(np.power(spike_count, boxcox) - 1)/boxcox \n\u001b[0;32m--> 146\u001b[0;31m                                          for spike_count in spike_counts])\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;31m# Filter the resulting spike counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nse/neural_control/loaders.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mboxcox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 spike_counts = np.array([(np.power(spike_count, boxcox) - 1)/boxcox \n\u001b[0;32m--> 146\u001b[0;31m                                          for spike_count in spike_counts])\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;31m# Filter the resulting spike counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate over the entire duration of the time series\n",
    "win = 5\n",
    "lags = [0, 3, 5, 10, 20]\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for data_file in tqdm(indy_files):\n",
    "    dat = load_sabes(data_file)\n",
    "    y = np.squeeze(dat['spike_rates'])\n",
    "    z = np.squeeze(dat['behavior'])\n",
    "\n",
    "    for lag in lags:\n",
    "\n",
    "        ylag = y[:-lag]\n",
    "        zlag = z[lag:]\n",
    "\n",
    "        # Y -> Z\n",
    "        di_yz = gaussian_DI(ylag, zlag, win)\n",
    "\n",
    "        ylag = y[lag:]\n",
    "        zlag = z[:-lag]\n",
    "\n",
    "        # Z -> y\n",
    "        di_zy = gaussian_DI(zlag, ylag, win)\n",
    "\n",
    "        idx_split = np.array_split(np.arange(y.shape[0]), 10)\n",
    "        di_zy10 = np.zeros(10)\n",
    "        di_yz10 = np.zeros(10)\n",
    "        \n",
    "        for i, idx in enumerate(idx_split):\n",
    "            \n",
    "            y_ = y[idx]\n",
    "            z_ = z[idx]\n",
    "\n",
    "            ylag = y_[:-lag]\n",
    "            zlag = z_[lag:]\n",
    "\n",
    "            di_yz10[i] = gaussian_DI(ylag, zlag, win)\n",
    "\n",
    "            ylag = y_[lag:]\n",
    "            zlag = z_[:-lag]\n",
    "\n",
    "            di_zy10[i] = gaussian_DI(zlag, ylag, win)\n",
    "\n",
    "        result = {}\n",
    "        result['data_file'] = data_file\n",
    "        result['lag'] = lag\n",
    "        result['di_yz'] = di_yz\n",
    "        result['di_zy'] = di_zy\n",
    "        result['di_yz10'] = di_yz10\n",
    "        result['di_zy10'] = di_zy10\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.74s/it]\n"
     ]
    }
   ],
   "source": [
    "dat = load_sabes(indy_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../segmentation.py:29: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  m = straight[1]/straight[0]\n"
     ]
    }
   ],
   "source": [
    "dat_segmented = reach_segment_sabes(dat, start_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [dat['spike_rates'][0, i1:i2] for i1, i2  in dat_segmented['transition_times']]\n",
    "z = [dat['behavior'][i1:i2] for i1, i2, in dat_segmented['transition_times']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9267784810566724"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_DI_trialized(y, z, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "``"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c52494c424e88c3f855a8aeb34b231af4706f7aa247f66fb47c890a5ab8814ab"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('dyn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
